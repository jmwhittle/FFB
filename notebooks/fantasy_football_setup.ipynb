{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "62d3c803",
   "metadata": {},
   "source": [
    "# Fantasy Football Database Setup with Sleeper API\n",
    "\n",
    "This notebook demonstrates setting up a PostgreSQL database for fantasy football statistics and connecting to the Sleeper API to collect data. We'll build the foundation for a comprehensive fantasy football analytics platform.\n",
    "\n",
    "## Project Overview\n",
    "- **Database**: PostgreSQL for robust data storage\n",
    "- **API**: Sleeper Fantasy Football platform\n",
    "- **Analytics**: Foundation for future data science workflows\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e3ed60c",
   "metadata": {},
   "source": [
    "## 1. Install Required Packages\n",
    "\n",
    "First, we'll install all the necessary Python packages for our fantasy football database project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a545b610",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sleeper-py\n",
      "  Downloading sleeper_py-1.0.1-py3-none-any.whl.metadata (4.4 kB)\n",
      "Collecting psycopg2-binary\n",
      "  Using cached psycopg2_binary-2.9.10-cp313-cp313-win_amd64.whl.metadata (4.8 kB)\n",
      "Collecting sqlalchemy\n",
      "  Using cached sqlalchemy-2.0.42-cp313-cp313-win_amd64.whl.metadata (9.8 kB)\n",
      "Collecting pandas\n",
      "  Using cached pandas-2.3.1-cp313-cp313-win_amd64.whl.metadata (19 kB)\n",
      "Collecting numpy\n",
      "  Downloading numpy-2.3.2-cp313-cp313-win_amd64.whl.metadata (60 kB)\n",
      "Collecting matplotlib\n",
      "  Using cached matplotlib-3.10.5-cp313-cp313-win_amd64.whl.metadata (11 kB)\n",
      "Collecting seaborn\n",
      "  Using cached seaborn-0.13.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting python-dotenv\n",
      "  Using cached python_dotenv-1.1.1-py3-none-any.whl.metadata (24 kB)\n",
      "Collecting requests\n",
      "  Using cached requests-2.32.4-py3-none-any.whl.metadata (4.9 kB)\n",
      "Collecting greenlet>=1 (from sqlalchemy)\n",
      "  Using cached greenlet-3.2.4-cp313-cp313-win_amd64.whl.metadata (4.2 kB)\n",
      "Collecting typing-extensions>=4.6.0 (from sqlalchemy)\n",
      "  Using cached typing_extensions-4.14.1-py3-none-any.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\jason\\ffb\\.venv\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Collecting pytz>=2020.1 (from pandas)\n",
      "  Using cached pytz-2025.2-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting tzdata>=2022.7 (from pandas)\n",
      "  Using cached tzdata-2025.2-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting contourpy>=1.0.1 (from matplotlib)\n",
      "  Using cached contourpy-1.3.3-cp313-cp313-win_amd64.whl.metadata (5.5 kB)\n",
      "Collecting cycler>=0.10 (from matplotlib)\n",
      "  Using cached cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting fonttools>=4.22.0 (from matplotlib)\n",
      "  Downloading fonttools-4.59.0-cp313-cp313-win_amd64.whl.metadata (110 kB)\n",
      "Collecting kiwisolver>=1.3.1 (from matplotlib)\n",
      "  Downloading kiwisolver-1.4.9-cp313-cp313-win_amd64.whl.metadata (6.4 kB)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\jason\\ffb\\.venv\\lib\\site-packages (from matplotlib) (25.0)\n",
      "Collecting pillow>=8 (from matplotlib)\n",
      "  Downloading pillow-11.3.0-cp313-cp313-win_amd64.whl.metadata (9.2 kB)\n",
      "Collecting pyparsing>=2.3.1 (from matplotlib)\n",
      "  Downloading pyparsing-3.2.3-py3-none-any.whl.metadata (5.0 kB)\n",
      "Collecting charset_normalizer<4,>=2 (from requests)\n",
      "  Using cached charset_normalizer-3.4.3-cp313-cp313-win_amd64.whl.metadata (37 kB)\n",
      "Collecting idna<4,>=2.5 (from requests)\n",
      "  Using cached idna-3.10-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting urllib3<3,>=1.21.1 (from requests)\n",
      "  Using cached urllib3-2.5.0-py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting certifi>=2017.4.17 (from requests)\n",
      "  Using cached certifi-2025.8.3-py3-none-any.whl.metadata (2.4 kB)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\jason\\ffb\\.venv\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Downloading sleeper_py-1.0.1-py3-none-any.whl (7.5 kB)\n",
      "Using cached psycopg2_binary-2.9.10-cp313-cp313-win_amd64.whl (2.6 MB)\n",
      "Using cached sqlalchemy-2.0.42-cp313-cp313-win_amd64.whl (2.1 MB)\n",
      "Using cached pandas-2.3.1-cp313-cp313-win_amd64.whl (11.0 MB)\n",
      "Downloading numpy-2.3.2-cp313-cp313-win_amd64.whl (12.8 MB)\n",
      "   ---------------------------------------- 0.0/12.8 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/12.8 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/12.8 MB ? eta -:--:--\n",
      "   --- ------------------------------------ 1.0/12.8 MB 6.3 MB/s eta 0:00:02\n",
      "   -------- ------------------------------- 2.6/12.8 MB 6.9 MB/s eta 0:00:02\n",
      "   ------------ --------------------------- 3.9/12.8 MB 6.6 MB/s eta 0:00:02\n",
      "   ----------------- ---------------------- 5.5/12.8 MB 6.8 MB/s eta 0:00:02\n",
      "   ---------------------- ----------------- 7.3/12.8 MB 7.1 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 8.7/12.8 MB 7.0 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 10.2/12.8 MB 7.1 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 12.1/12.8 MB 7.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 12.8/12.8 MB 7.1 MB/s  0:00:02\n",
      "Downloading matplotlib-3.10.5-cp313-cp313-win_amd64.whl (8.1 MB)\n",
      "   ---------------------------------------- 0.0/8.1 MB ? eta -:--:--\n",
      "   ------ --------------------------------- 1.3/8.1 MB 6.1 MB/s eta 0:00:02\n",
      "   ------------ --------------------------- 2.6/8.1 MB 6.4 MB/s eta 0:00:01\n",
      "   ------------------ --------------------- 3.7/8.1 MB 5.8 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 5.2/8.1 MB 6.1 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 6.0/8.1 MB 5.7 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 7.1/8.1 MB 5.6 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 7.9/8.1 MB 5.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 8.1/8.1 MB 5.4 MB/s  0:00:01\n",
      "Downloading seaborn-0.13.2-py3-none-any.whl (294 kB)\n",
      "Using cached python_dotenv-1.1.1-py3-none-any.whl (20 kB)\n",
      "Using cached requests-2.32.4-py3-none-any.whl (64 kB)\n",
      "Using cached charset_normalizer-3.4.3-cp313-cp313-win_amd64.whl (107 kB)\n",
      "Using cached idna-3.10-py3-none-any.whl (70 kB)\n",
      "Using cached urllib3-2.5.0-py3-none-any.whl (129 kB)\n",
      "Using cached certifi-2025.8.3-py3-none-any.whl (161 kB)\n",
      "Downloading contourpy-1.3.3-cp313-cp313-win_amd64.whl (226 kB)\n",
      "Downloading cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
      "Downloading fonttools-4.59.0-cp313-cp313-win_amd64.whl (2.2 MB)\n",
      "   ---------------------------------------- 0.0/2.2 MB ? eta -:--:--\n",
      "   ------------------ --------------------- 1.0/2.2 MB 5.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.2/2.2 MB 5.5 MB/s  0:00:00\n",
      "Using cached greenlet-3.2.4-cp313-cp313-win_amd64.whl (299 kB)\n",
      "Downloading kiwisolver-1.4.9-cp313-cp313-win_amd64.whl (73 kB)\n",
      "Downloading pillow-11.3.0-cp313-cp313-win_amd64.whl (7.0 MB)\n",
      "   ---------------------------------------- 0.0/7.0 MB ? eta -:--:--\n",
      "   ------ --------------------------------- 1.0/7.0 MB 7.8 MB/s eta 0:00:01\n",
      "   ---------------- ----------------------- 2.9/7.0 MB 7.0 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 4.5/7.0 MB 7.2 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 5.2/7.0 MB 6.6 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 5.5/7.0 MB 5.5 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 6.6/7.0 MB 5.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 7.0/7.0 MB 4.9 MB/s  0:00:01\n",
      "Downloading pyparsing-3.2.3-py3-none-any.whl (111 kB)\n",
      "Using cached pytz-2025.2-py2.py3-none-any.whl (509 kB)\n",
      "Using cached typing_extensions-4.14.1-py3-none-any.whl (43 kB)\n",
      "Using cached tzdata-2025.2-py2.py3-none-any.whl (347 kB)\n",
      "Installing collected packages: pytz, urllib3, tzdata, typing-extensions, python-dotenv, pyparsing, psycopg2-binary, pillow, numpy, kiwisolver, idna, greenlet, fonttools, cycler, charset_normalizer, certifi, sqlalchemy, requests, pandas, contourpy, sleeper-py, matplotlib, seaborn\n",
      "\n",
      "   ----------------------------------------  0/23 [pytz]\n",
      "   ----------------------------------------  0/23 [pytz]\n",
      "   ----------------------------------------  0/23 [pytz]\n",
      "   - --------------------------------------  1/23 [urllib3]\n",
      "   - --------------------------------------  1/23 [urllib3]\n",
      "   - --------------------------------------  1/23 [urllib3]\n",
      "   - --------------------------------------  1/23 [urllib3]\n",
      "   - --------------------------------------  1/23 [urllib3]\n",
      "   --- ------------------------------------  2/23 [tzdata]\n",
      "   --- ------------------------------------  2/23 [tzdata]\n",
      "   --- ------------------------------------  2/23 [tzdata]\n",
      "   --- ------------------------------------  2/23 [tzdata]\n",
      "   ----- ----------------------------------  3/23 [typing-extensions]\n",
      "   ------ ---------------------------------  4/23 [python-dotenv]\n",
      "   -------- -------------------------------  5/23 [pyparsing]\n",
      "   -------- -------------------------------  5/23 [pyparsing]\n",
      "   ---------- -----------------------------  6/23 [psycopg2-binary]\n",
      "   ---------- -----------------------------  6/23 [psycopg2-binary]\n",
      "   ------------ ---------------------------  7/23 [pillow]\n",
      "   ------------ ---------------------------  7/23 [pillow]\n",
      "   ------------ ---------------------------  7/23 [pillow]\n",
      "   ------------ ---------------------------  7/23 [pillow]\n",
      "   ------------ ---------------------------  7/23 [pillow]\n",
      "   ------------ ---------------------------  7/23 [pillow]\n",
      "   ------------ ---------------------------  7/23 [pillow]\n",
      "   ------------ ---------------------------  7/23 [pillow]\n",
      "   ------------ ---------------------------  7/23 [pillow]\n",
      "   ------------ ---------------------------  7/23 [pillow]\n",
      "   ------------ ---------------------------  7/23 [pillow]\n",
      "   ------------ ---------------------------  7/23 [pillow]\n",
      "   ------------ ---------------------------  7/23 [pillow]\n",
      "   ------------ ---------------------------  7/23 [pillow]\n",
      "   ------------- --------------------------  8/23 [numpy]\n",
      "   ------------- --------------------------  8/23 [numpy]\n",
      "   ------------- --------------------------  8/23 [numpy]\n",
      "   ------------- --------------------------  8/23 [numpy]\n",
      "   ------------- --------------------------  8/23 [numpy]\n",
      "   ------------- --------------------------  8/23 [numpy]\n",
      "   ------------- --------------------------  8/23 [numpy]\n",
      "   ------------- --------------------------  8/23 [numpy]\n",
      "   ------------- --------------------------  8/23 [numpy]\n",
      "   ------------- --------------------------  8/23 [numpy]\n",
      "   ------------- --------------------------  8/23 [numpy]\n",
      "   ------------- --------------------------  8/23 [numpy]\n",
      "   ------------- --------------------------  8/23 [numpy]\n",
      "   ------------- --------------------------  8/23 [numpy]\n",
      "   ------------- --------------------------  8/23 [numpy]\n",
      "   ------------- --------------------------  8/23 [numpy]\n",
      "   ------------- --------------------------  8/23 [numpy]\n",
      "   ------------- --------------------------  8/23 [numpy]\n",
      "   ------------- --------------------------  8/23 [numpy]\n",
      "   ------------- --------------------------  8/23 [numpy]\n",
      "   ------------- --------------------------  8/23 [numpy]\n",
      "   ------------- --------------------------  8/23 [numpy]\n",
      "   ------------- --------------------------  8/23 [numpy]\n",
      "   ------------- --------------------------  8/23 [numpy]\n",
      "   ------------- --------------------------  8/23 [numpy]\n",
      "   ------------- --------------------------  8/23 [numpy]\n",
      "   ------------- --------------------------  8/23 [numpy]\n",
      "   ------------- --------------------------  8/23 [numpy]\n",
      "   ------------- --------------------------  8/23 [numpy]\n",
      "   ------------- --------------------------  8/23 [numpy]\n",
      "   ------------- --------------------------  8/23 [numpy]\n",
      "   ------------- --------------------------  8/23 [numpy]\n",
      "   ------------- --------------------------  8/23 [numpy]\n",
      "   ------------- --------------------------  8/23 [numpy]\n",
      "   ------------- --------------------------  8/23 [numpy]\n",
      "   ------------- --------------------------  8/23 [numpy]\n",
      "   ------------- --------------------------  8/23 [numpy]\n",
      "   ------------- --------------------------  8/23 [numpy]\n",
      "   ------------- --------------------------  8/23 [numpy]\n",
      "   ------------- --------------------------  8/23 [numpy]\n",
      "   ------------- --------------------------  8/23 [numpy]\n",
      "   ------------- --------------------------  8/23 [numpy]\n",
      "   ------------- --------------------------  8/23 [numpy]\n",
      "   ------------- --------------------------  8/23 [numpy]\n",
      "   ------------- --------------------------  8/23 [numpy]\n",
      "   ------------- --------------------------  8/23 [numpy]\n",
      "   ------------- --------------------------  8/23 [numpy]\n",
      "   ------------- --------------------------  8/23 [numpy]\n",
      "   ------------- --------------------------  8/23 [numpy]\n",
      "   ------------- --------------------------  8/23 [numpy]\n",
      "   ------------- --------------------------  8/23 [numpy]\n",
      "   ------------- --------------------------  8/23 [numpy]\n",
      "   ------------- --------------------------  8/23 [numpy]\n",
      "   ----------------- ---------------------- 10/23 [idna]\n",
      "   ----------------- ---------------------- 10/23 [idna]\n",
      "   ------------------- -------------------- 11/23 [greenlet]\n",
      "   ------------------- -------------------- 11/23 [greenlet]\n",
      "   -------------------- ------------------- 12/23 [fonttools]\n",
      "   -------------------- ------------------- 12/23 [fonttools]\n",
      "   -------------------- ------------------- 12/23 [fonttools]\n",
      "   -------------------- ------------------- 12/23 [fonttools]\n",
      "   -------------------- ------------------- 12/23 [fonttools]\n",
      "   -------------------- ------------------- 12/23 [fonttools]\n",
      "   -------------------- ------------------- 12/23 [fonttools]\n",
      "   -------------------- ------------------- 12/23 [fonttools]\n",
      "   -------------------- ------------------- 12/23 [fonttools]\n",
      "   -------------------- ------------------- 12/23 [fonttools]\n",
      "   -------------------- ------------------- 12/23 [fonttools]\n",
      "   -------------------- ------------------- 12/23 [fonttools]\n",
      "   -------------------- ------------------- 12/23 [fonttools]\n",
      "   -------------------- ------------------- 12/23 [fonttools]\n",
      "   -------------------- ------------------- 12/23 [fonttools]\n",
      "   -------------------- ------------------- 12/23 [fonttools]\n",
      "   -------------------- ------------------- 12/23 [fonttools]\n",
      "   -------------------- ------------------- 12/23 [fonttools]\n",
      "   -------------------- ------------------- 12/23 [fonttools]\n",
      "   -------------------- ------------------- 12/23 [fonttools]\n",
      "   -------------------- ------------------- 12/23 [fonttools]\n",
      "   -------------------- ------------------- 12/23 [fonttools]\n",
      "   -------------------- ------------------- 12/23 [fonttools]\n",
      "   -------------------- ------------------- 12/23 [fonttools]\n",
      "   -------------------- ------------------- 12/23 [fonttools]\n",
      "   -------------------- ------------------- 12/23 [fonttools]\n",
      "   -------------------- ------------------- 12/23 [fonttools]\n",
      "   -------------------- ------------------- 12/23 [fonttools]\n",
      "   -------------------- ------------------- 12/23 [fonttools]\n",
      "   -------------------- ------------------- 12/23 [fonttools]\n",
      "   -------------------- ------------------- 12/23 [fonttools]\n",
      "   -------------------- ------------------- 12/23 [fonttools]\n",
      "   -------------------- ------------------- 12/23 [fonttools]\n",
      "   -------------------- ------------------- 12/23 [fonttools]\n",
      "   -------------------- ------------------- 12/23 [fonttools]\n",
      "   ---------------------- ----------------- 13/23 [cycler]\n",
      "   ------------------------ --------------- 14/23 [charset_normalizer]\n",
      "   -------------------------- ------------- 15/23 [certifi]\n",
      "   --------------------------- ------------ 16/23 [sqlalchemy]\n",
      "   --------------------------- ------------ 16/23 [sqlalchemy]\n",
      "   --------------------------- ------------ 16/23 [sqlalchemy]\n",
      "   --------------------------- ------------ 16/23 [sqlalchemy]\n",
      "   --------------------------- ------------ 16/23 [sqlalchemy]\n",
      "   --------------------------- ------------ 16/23 [sqlalchemy]\n",
      "   --------------------------- ------------ 16/23 [sqlalchemy]\n",
      "   --------------------------- ------------ 16/23 [sqlalchemy]\n",
      "   --------------------------- ------------ 16/23 [sqlalchemy]\n",
      "   --------------------------- ------------ 16/23 [sqlalchemy]\n",
      "   --------------------------- ------------ 16/23 [sqlalchemy]\n",
      "   --------------------------- ------------ 16/23 [sqlalchemy]\n",
      "   --------------------------- ------------ 16/23 [sqlalchemy]\n",
      "   --------------------------- ------------ 16/23 [sqlalchemy]\n",
      "   --------------------------- ------------ 16/23 [sqlalchemy]\n",
      "   --------------------------- ------------ 16/23 [sqlalchemy]\n",
      "   --------------------------- ------------ 16/23 [sqlalchemy]\n",
      "   --------------------------- ------------ 16/23 [sqlalchemy]\n",
      "   --------------------------- ------------ 16/23 [sqlalchemy]\n",
      "   --------------------------- ------------ 16/23 [sqlalchemy]\n",
      "   --------------------------- ------------ 16/23 [sqlalchemy]\n",
      "   --------------------------- ------------ 16/23 [sqlalchemy]\n",
      "   --------------------------- ------------ 16/23 [sqlalchemy]\n",
      "   --------------------------- ------------ 16/23 [sqlalchemy]\n",
      "   --------------------------- ------------ 16/23 [sqlalchemy]\n",
      "   --------------------------- ------------ 16/23 [sqlalchemy]\n",
      "   --------------------------- ------------ 16/23 [sqlalchemy]\n",
      "   --------------------------- ------------ 16/23 [sqlalchemy]\n",
      "   --------------------------- ------------ 16/23 [sqlalchemy]\n",
      "   --------------------------- ------------ 16/23 [sqlalchemy]\n",
      "   --------------------------- ------------ 16/23 [sqlalchemy]\n",
      "   --------------------------- ------------ 16/23 [sqlalchemy]\n",
      "   ----------------------------- ---------- 17/23 [requests]\n",
      "   ----------------------------- ---------- 17/23 [requests]\n",
      "   ------------------------------- -------- 18/23 [pandas]\n",
      "   ------------------------------- -------- 18/23 [pandas]\n",
      "   ------------------------------- -------- 18/23 [pandas]\n",
      "   ------------------------------- -------- 18/23 [pandas]\n",
      "   ------------------------------- -------- 18/23 [pandas]\n",
      "   ------------------------------- -------- 18/23 [pandas]\n",
      "   ------------------------------- -------- 18/23 [pandas]\n",
      "   ------------------------------- -------- 18/23 [pandas]\n",
      "   ------------------------------- -------- 18/23 [pandas]\n",
      "   ------------------------------- -------- 18/23 [pandas]\n",
      "   ------------------------------- -------- 18/23 [pandas]\n",
      "   ------------------------------- -------- 18/23 [pandas]\n",
      "   ------------------------------- -------- 18/23 [pandas]\n",
      "   ------------------------------- -------- 18/23 [pandas]\n",
      "   ------------------------------- -------- 18/23 [pandas]\n",
      "   ------------------------------- -------- 18/23 [pandas]\n",
      "   ------------------------------- -------- 18/23 [pandas]\n",
      "   ------------------------------- -------- 18/23 [pandas]\n",
      "   ------------------------------- -------- 18/23 [pandas]\n",
      "   ------------------------------- -------- 18/23 [pandas]\n",
      "   ------------------------------- -------- 18/23 [pandas]\n",
      "   ------------------------------- -------- 18/23 [pandas]\n",
      "   ------------------------------- -------- 18/23 [pandas]\n",
      "   ------------------------------- -------- 18/23 [pandas]\n",
      "   ------------------------------- -------- 18/23 [pandas]\n",
      "   ------------------------------- -------- 18/23 [pandas]\n",
      "   ------------------------------- -------- 18/23 [pandas]\n",
      "   ------------------------------- -------- 18/23 [pandas]\n",
      "   ------------------------------- -------- 18/23 [pandas]\n",
      "   ------------------------------- -------- 18/23 [pandas]\n",
      "   ------------------------------- -------- 18/23 [pandas]\n",
      "   ------------------------------- -------- 18/23 [pandas]\n",
      "   ------------------------------- -------- 18/23 [pandas]\n",
      "   ------------------------------- -------- 18/23 [pandas]\n",
      "   ------------------------------- -------- 18/23 [pandas]\n",
      "   ------------------------------- -------- 18/23 [pandas]\n",
      "   ------------------------------- -------- 18/23 [pandas]\n",
      "   ------------------------------- -------- 18/23 [pandas]\n",
      "   ------------------------------- -------- 18/23 [pandas]\n",
      "   ------------------------------- -------- 18/23 [pandas]\n",
      "   ------------------------------- -------- 18/23 [pandas]\n",
      "   ------------------------------- -------- 18/23 [pandas]\n",
      "   ------------------------------- -------- 18/23 [pandas]\n",
      "   ------------------------------- -------- 18/23 [pandas]\n",
      "   ------------------------------- -------- 18/23 [pandas]\n",
      "   ------------------------------- -------- 18/23 [pandas]\n",
      "   ------------------------------- -------- 18/23 [pandas]\n",
      "   ------------------------------- -------- 18/23 [pandas]\n",
      "   ------------------------------- -------- 18/23 [pandas]\n",
      "   ------------------------------- -------- 18/23 [pandas]\n",
      "   ------------------------------- -------- 18/23 [pandas]\n",
      "   ------------------------------- -------- 18/23 [pandas]\n",
      "   ------------------------------- -------- 18/23 [pandas]\n",
      "   ------------------------------- -------- 18/23 [pandas]\n",
      "   ------------------------------- -------- 18/23 [pandas]\n",
      "   ------------------------------- -------- 18/23 [pandas]\n",
      "   ------------------------------- -------- 18/23 [pandas]\n",
      "   ------------------------------- -------- 18/23 [pandas]\n",
      "   ------------------------------- -------- 18/23 [pandas]\n",
      "   ------------------------------- -------- 18/23 [pandas]\n",
      "   ------------------------------- -------- 18/23 [pandas]\n",
      "   ------------------------------- -------- 18/23 [pandas]\n",
      "   ------------------------------- -------- 18/23 [pandas]\n",
      "   ------------------------------- -------- 18/23 [pandas]\n",
      "   ------------------------------- -------- 18/23 [pandas]\n",
      "   ------------------------------- -------- 18/23 [pandas]\n",
      "   ------------------------------- -------- 18/23 [pandas]\n",
      "   ------------------------------- -------- 18/23 [pandas]\n",
      "   ------------------------------- -------- 18/23 [pandas]\n",
      "   ------------------------------- -------- 18/23 [pandas]\n",
      "   ------------------------------- -------- 18/23 [pandas]\n",
      "   ------------------------------- -------- 18/23 [pandas]\n",
      "   ------------------------------- -------- 18/23 [pandas]\n",
      "   ------------------------------- -------- 18/23 [pandas]\n",
      "   ------------------------------- -------- 18/23 [pandas]\n",
      "   ------------------------------- -------- 18/23 [pandas]\n",
      "   ------------------------------- -------- 18/23 [pandas]\n",
      "   ------------------------------- -------- 18/23 [pandas]\n",
      "   ------------------------------- -------- 18/23 [pandas]\n",
      "   ------------------------------- -------- 18/23 [pandas]\n",
      "   ------------------------------- -------- 18/23 [pandas]\n",
      "   ------------------------------- -------- 18/23 [pandas]\n",
      "   ------------------------------- -------- 18/23 [pandas]\n",
      "   ------------------------------- -------- 18/23 [pandas]\n",
      "   ------------------------------- -------- 18/23 [pandas]\n",
      "   ------------------------------- -------- 18/23 [pandas]\n",
      "   ------------------------------- -------- 18/23 [pandas]\n",
      "   ------------------------------- -------- 18/23 [pandas]\n",
      "   ------------------------------- -------- 18/23 [pandas]\n",
      "   ------------------------------- -------- 18/23 [pandas]\n",
      "   ------------------------------- -------- 18/23 [pandas]\n",
      "   ------------------------------- -------- 18/23 [pandas]\n",
      "   ------------------------------- -------- 18/23 [pandas]\n",
      "   ------------------------------- -------- 18/23 [pandas]\n",
      "   ------------------------------- -------- 18/23 [pandas]\n",
      "   ------------------------------- -------- 18/23 [pandas]\n",
      "   ------------------------------- -------- 18/23 [pandas]\n",
      "   ------------------------------- -------- 18/23 [pandas]\n",
      "   ------------------------------- -------- 18/23 [pandas]\n",
      "   ------------------------------- -------- 18/23 [pandas]\n",
      "   ------------------------------- -------- 18/23 [pandas]\n",
      "   ------------------------------- -------- 18/23 [pandas]\n",
      "   ------------------------------- -------- 18/23 [pandas]\n",
      "   ------------------------------- -------- 18/23 [pandas]\n",
      "   ------------------------------- -------- 18/23 [pandas]\n",
      "   ------------------------------- -------- 18/23 [pandas]\n",
      "   ------------------------------- -------- 18/23 [pandas]\n",
      "   ------------------------------- -------- 18/23 [pandas]\n",
      "   ------------------------------- -------- 18/23 [pandas]\n",
      "   ------------------------------- -------- 18/23 [pandas]\n",
      "   ------------------------------- -------- 18/23 [pandas]\n",
      "   ------------------------------- -------- 18/23 [pandas]\n",
      "   ------------------------------- -------- 18/23 [pandas]\n",
      "   ------------------------------- -------- 18/23 [pandas]\n",
      "   ------------------------------- -------- 18/23 [pandas]\n",
      "   ------------------------------- -------- 18/23 [pandas]\n",
      "   ------------------------------- -------- 18/23 [pandas]\n",
      "   ------------------------------- -------- 18/23 [pandas]\n",
      "   ------------------------------- -------- 18/23 [pandas]\n",
      "   ------------------------------- -------- 18/23 [pandas]\n",
      "   ------------------------------- -------- 18/23 [pandas]\n",
      "   ------------------------------- -------- 18/23 [pandas]\n",
      "   ------------------------------- -------- 18/23 [pandas]\n",
      "   ------------------------------- -------- 18/23 [pandas]\n",
      "   ------------------------------- -------- 18/23 [pandas]\n",
      "   ------------------------------- -------- 18/23 [pandas]\n",
      "   ------------------------------- -------- 18/23 [pandas]\n",
      "   ------------------------------- -------- 18/23 [pandas]\n",
      "   ------------------------------- -------- 18/23 [pandas]\n",
      "   ------------------------------- -------- 18/23 [pandas]\n",
      "   ------------------------------- -------- 18/23 [pandas]\n",
      "   ------------------------------- -------- 18/23 [pandas]\n",
      "   ------------------------------- -------- 18/23 [pandas]\n",
      "   ------------------------------- -------- 18/23 [pandas]\n",
      "   ------------------------------- -------- 18/23 [pandas]\n",
      "   ------------------------------- -------- 18/23 [pandas]\n",
      "   ------------------------------- -------- 18/23 [pandas]\n",
      "   ------------------------------- -------- 18/23 [pandas]\n",
      "   ------------------------------- -------- 18/23 [pandas]\n",
      "   ------------------------------- -------- 18/23 [pandas]\n",
      "   ------------------------------- -------- 18/23 [pandas]\n",
      "   ------------------------------- -------- 18/23 [pandas]\n",
      "   ------------------------------- -------- 18/23 [pandas]\n",
      "   ------------------------------- -------- 18/23 [pandas]\n",
      "   --------------------------------- ------ 19/23 [contourpy]\n",
      "   --------------------------------- ------ 19/23 [contourpy]\n",
      "   ------------------------------------ --- 21/23 [matplotlib]\n",
      "   ------------------------------------ --- 21/23 [matplotlib]\n",
      "   ------------------------------------ --- 21/23 [matplotlib]\n",
      "   ------------------------------------ --- 21/23 [matplotlib]\n",
      "   ------------------------------------ --- 21/23 [matplotlib]\n",
      "   ------------------------------------ --- 21/23 [matplotlib]\n",
      "   ------------------------------------ --- 21/23 [matplotlib]\n",
      "   ------------------------------------ --- 21/23 [matplotlib]\n",
      "   ------------------------------------ --- 21/23 [matplotlib]\n",
      "   ------------------------------------ --- 21/23 [matplotlib]\n",
      "   ------------------------------------ --- 21/23 [matplotlib]\n",
      "   ------------------------------------ --- 21/23 [matplotlib]\n",
      "   ------------------------------------ --- 21/23 [matplotlib]\n",
      "   ------------------------------------ --- 21/23 [matplotlib]\n",
      "   ------------------------------------ --- 21/23 [matplotlib]\n",
      "   ------------------------------------ --- 21/23 [matplotlib]\n",
      "   ------------------------------------ --- 21/23 [matplotlib]\n",
      "   ------------------------------------ --- 21/23 [matplotlib]\n",
      "   ------------------------------------ --- 21/23 [matplotlib]\n",
      "   ------------------------------------ --- 21/23 [matplotlib]\n",
      "   ------------------------------------ --- 21/23 [matplotlib]\n",
      "   ------------------------------------ --- 21/23 [matplotlib]\n",
      "   ------------------------------------ --- 21/23 [matplotlib]\n",
      "   ------------------------------------ --- 21/23 [matplotlib]\n",
      "   ------------------------------------ --- 21/23 [matplotlib]\n",
      "   ------------------------------------ --- 21/23 [matplotlib]\n",
      "   ------------------------------------ --- 21/23 [matplotlib]\n",
      "   ------------------------------------ --- 21/23 [matplotlib]\n",
      "   ------------------------------------ --- 21/23 [matplotlib]\n",
      "   ------------------------------------ --- 21/23 [matplotlib]\n",
      "   ------------------------------------ --- 21/23 [matplotlib]\n",
      "   ------------------------------------ --- 21/23 [matplotlib]\n",
      "   ------------------------------------ --- 21/23 [matplotlib]\n",
      "   ------------------------------------ --- 21/23 [matplotlib]\n",
      "   ------------------------------------ --- 21/23 [matplotlib]\n",
      "   ------------------------------------ --- 21/23 [matplotlib]\n",
      "   ------------------------------------ --- 21/23 [matplotlib]\n",
      "   ------------------------------------ --- 21/23 [matplotlib]\n",
      "   -------------------------------------- - 22/23 [seaborn]\n",
      "   -------------------------------------- - 22/23 [seaborn]\n",
      "   -------------------------------------- - 22/23 [seaborn]\n",
      "   -------------------------------------- - 22/23 [seaborn]\n",
      "   -------------------------------------- - 22/23 [seaborn]\n",
      "   -------------------------------------- - 22/23 [seaborn]\n",
      "   -------------------------------------- - 22/23 [seaborn]\n",
      "   ---------------------------------------- 23/23 [seaborn]\n",
      "\n",
      "Successfully installed certifi-2025.8.3 charset_normalizer-3.4.3 contourpy-1.3.3 cycler-0.12.1 fonttools-4.59.0 greenlet-3.2.4 idna-3.10 kiwisolver-1.4.9 matplotlib-3.10.5 numpy-2.3.2 pandas-2.3.1 pillow-11.3.0 psycopg2-binary-2.9.10 pyparsing-3.2.3 python-dotenv-1.1.1 pytz-2025.2 requests-2.32.4 seaborn-0.13.2 sleeper-py-1.0.1 sqlalchemy-2.0.42 typing-extensions-4.14.1 tzdata-2025.2 urllib3-2.5.0\n"
     ]
    }
   ],
   "source": [
    "# Install required packages\n",
    "!pip install sleeper-py psycopg2-binary sqlalchemy pandas numpy matplotlib seaborn python-dotenv requests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "183d6bee",
   "metadata": {},
   "source": [
    "## 2. Import Libraries and Dependencies\n",
    "\n",
    "Import all the libraries we'll need for database operations, API calls, and data analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7c6db94e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries imported successfully!\n"
     ]
    }
   ],
   "source": [
    "# Core libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import requests\n",
    "import json\n",
    "from datetime import datetime, timedelta\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Database libraries\n",
    "import psycopg2\n",
    "from sqlalchemy import create_engine, text\n",
    "import sqlalchemy as sa\n",
    "\n",
    "# Set display options\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', None)\n",
    "plt.style.use('seaborn-v0_8')\n",
    "\n",
    "print(\"Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3d9002f",
   "metadata": {},
   "source": [
    "## 3. Database Setup and Connection\n",
    "\n",
    "Configure PostgreSQL connection and create database engine. Make sure you have PostgreSQL installed and running."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7294a447",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected to PostgreSQL: PostgreSQL 17.5 on x86_64-windows, compiled by msv...\n"
     ]
    }
   ],
   "source": [
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Database configuration\n",
    "DB_CONFIG = {\n",
    "    'host': os.getenv('DB_HOST', 'localhost'),\n",
    "    'port': os.getenv('DB_PORT', '5432'),\n",
    "    'database': os.getenv('DB_NAME', 'ffb_stats'),\n",
    "    'user': os.getenv('DB_USER', 'postgres'),\n",
    "    'password': os.getenv('DB_PASSWORD', 'your_password')\n",
    "}\n",
    "\n",
    "# Create connection string\n",
    "connection_string = f\"postgresql://{DB_CONFIG['user']}:{DB_CONFIG['password']}@{DB_CONFIG['host']}:{DB_CONFIG['port']}/{DB_CONFIG['database']}\"\n",
    "\n",
    "# Create SQLAlchemy engine\n",
    "try:\n",
    "    engine = create_engine(connection_string, echo=False)\n",
    "    \n",
    "    # Test connection\n",
    "    with engine.connect() as conn:\n",
    "        result = conn.execute(text(\"SELECT version()\"))\n",
    "        version = result.fetchone()[0]\n",
    "        print(f\"Connected to PostgreSQL: {version[:50]}...\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"Database connection failed: {e}\")\n",
    "    print(\"Please ensure PostgreSQL is running and credentials are correct.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72cc9599",
   "metadata": {},
   "source": [
    "## 4. Create Database Schema\n",
    "\n",
    "Define and create the initial database schema for our fantasy football data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7d3d3d17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Created table: users\n",
      "✓ Created table: leagues\n",
      "✓ Created table: players\n",
      "✓ Created table: rosters\n",
      "✓ Created table: matchups\n",
      "\n",
      "Database schema created successfully!\n"
     ]
    }
   ],
   "source": [
    "# SQL schema definitions\n",
    "schema_sql = {\n",
    "    'users': \"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS users (\n",
    "        id VARCHAR PRIMARY KEY,\n",
    "        username VARCHAR UNIQUE NOT NULL,\n",
    "        display_name VARCHAR,\n",
    "        avatar VARCHAR,\n",
    "        created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,\n",
    "        updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP\n",
    "    )\n",
    "    \"\"\",\n",
    "    \n",
    "    'leagues': \"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS leagues (\n",
    "        id VARCHAR PRIMARY KEY,\n",
    "        name VARCHAR NOT NULL,\n",
    "        season VARCHAR NOT NULL,\n",
    "        sport VARCHAR DEFAULT 'nfl',\n",
    "        status VARCHAR,\n",
    "        season_type VARCHAR,\n",
    "        total_rosters INTEGER,\n",
    "        scoring_settings JSONB,\n",
    "        roster_positions JSONB,\n",
    "        settings JSONB,\n",
    "        created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,\n",
    "        updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP\n",
    "    )\n",
    "    \"\"\",\n",
    "    \n",
    "    'players': \"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS players (\n",
    "        id VARCHAR PRIMARY KEY,\n",
    "        player_id VARCHAR UNIQUE,\n",
    "        first_name VARCHAR,\n",
    "        last_name VARCHAR,\n",
    "        full_name VARCHAR,\n",
    "        position VARCHAR,\n",
    "        team VARCHAR,\n",
    "        college VARCHAR,\n",
    "        height VARCHAR,\n",
    "        weight VARCHAR,\n",
    "        age INTEGER,\n",
    "        years_exp INTEGER,\n",
    "        active BOOLEAN DEFAULT TRUE,\n",
    "        injury_status VARCHAR,\n",
    "        fantasy_data_id VARCHAR,\n",
    "        created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,\n",
    "        updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP\n",
    "    )\n",
    "    \"\"\",\n",
    "    \n",
    "    'rosters': \"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS rosters (\n",
    "        id SERIAL PRIMARY KEY,\n",
    "        roster_id INTEGER NOT NULL,\n",
    "        league_id VARCHAR REFERENCES leagues(id),\n",
    "        owner_id VARCHAR REFERENCES users(id),\n",
    "        co_owners JSONB,\n",
    "        wins INTEGER DEFAULT 0,\n",
    "        losses INTEGER DEFAULT 0,\n",
    "        ties INTEGER DEFAULT 0,\n",
    "        waiver_position INTEGER,\n",
    "        waiver_budget_used INTEGER DEFAULT 0,\n",
    "        total_moves INTEGER DEFAULT 0,\n",
    "        settings JSONB,\n",
    "        created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,\n",
    "        updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP\n",
    "    )\n",
    "    \"\"\",\n",
    "    \n",
    "    'matchups': \"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS matchups (\n",
    "        id SERIAL PRIMARY KEY,\n",
    "        matchup_id INTEGER,\n",
    "        league_id VARCHAR REFERENCES leagues(id),\n",
    "        roster_id INTEGER,\n",
    "        week INTEGER NOT NULL,\n",
    "        points DECIMAL,\n",
    "        points_against DECIMAL,\n",
    "        starters JSONB,\n",
    "        starters_points JSONB,\n",
    "        players JSONB,\n",
    "        players_points JSONB,\n",
    "        custom_points DECIMAL,\n",
    "        created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP\n",
    "    )\n",
    "    \"\"\"\n",
    "}\n",
    "\n",
    "# Create tables\n",
    "try:\n",
    "    with engine.connect() as conn:\n",
    "        for table_name, sql in schema_sql.items():\n",
    "            conn.execute(text(sql))\n",
    "            print(f\"✓ Created table: {table_name}\")\n",
    "        conn.commit()\n",
    "    print(\"\\nDatabase schema created successfully!\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Error creating schema: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "210ac25a",
   "metadata": {},
   "source": [
    "## 5. Initialize Sleeper API Client\n",
    "\n",
    "Set up the Sleeper API client and test connectivity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fb92d86a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Sleeper API connectivity...\n",
      "✓ Connected to Sleeper API\n",
      "Current NFL Season: 2025\n",
      "Current Week: 1\n",
      "Season Type: pre\n",
      "✓ Connected to Sleeper API\n",
      "Current NFL Season: 2025\n",
      "Current Week: 1\n",
      "Season Type: pre\n"
     ]
    }
   ],
   "source": [
    "class SleeperAPI:\n",
    "    \"\"\"Simple Sleeper API client.\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.base_url = \"https://api.sleeper.app/v1\"\n",
    "        \n",
    "    def get(self, endpoint):\n",
    "        \"\"\"Make GET request to Sleeper API.\"\"\"\n",
    "        url = f\"{self.base_url}/{endpoint}\"\n",
    "        try:\n",
    "            response = requests.get(url, timeout=30)\n",
    "            response.raise_for_status()\n",
    "            return response.json()\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            print(f\"API request failed: {e}\")\n",
    "            return None\n",
    "    \n",
    "    def get_nfl_state(self):\n",
    "        \"\"\"Get current NFL season state.\"\"\"\n",
    "        return self.get(\"state/nfl\")\n",
    "    \n",
    "    def get_user(self, username):\n",
    "        \"\"\"Get user by username.\"\"\"\n",
    "        return self.get(f\"user/{username}\")\n",
    "    \n",
    "    def get_user_leagues(self, user_id, sport=\"nfl\", season=\"2024\"):\n",
    "        \"\"\"Get user's leagues.\"\"\"\n",
    "        return self.get(f\"user/{user_id}/leagues/{sport}/{season}\")\n",
    "    \n",
    "    def get_players(self, sport=\"nfl\"):\n",
    "        \"\"\"Get all players.\"\"\"\n",
    "        return self.get(f\"players/{sport}\")\n",
    "    \n",
    "    def get_league_rosters(self, league_id):\n",
    "        \"\"\"Get league rosters.\"\"\"\n",
    "        return self.get(f\"league/{league_id}/rosters\")\n",
    "    \n",
    "    def get_league_matchups(self, league_id, week):\n",
    "        \"\"\"Get league matchups for a week.\"\"\"\n",
    "        return self.get(f\"league/{league_id}/matchups/{week}\")\n",
    "\n",
    "# Initialize API client\n",
    "sleeper = SleeperAPI()\n",
    "\n",
    "# Test API connectivity\n",
    "print(\"Testing Sleeper API connectivity...\")\n",
    "nfl_state = sleeper.get_nfl_state()\n",
    "\n",
    "if nfl_state:\n",
    "    print(f\"✓ Connected to Sleeper API\")\n",
    "    print(f\"Current NFL Season: {nfl_state.get('season')}\")\n",
    "    print(f\"Current Week: {nfl_state.get('week')}\")\n",
    "    print(f\"Season Type: {nfl_state.get('season_type')}\")\n",
    "else:\n",
    "    print(\"✗ Failed to connect to Sleeper API\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e01caa6",
   "metadata": {},
   "source": [
    "## 6. Fetch Sample Data from Sleeper API\n",
    "\n",
    "Retrieve sample data from the Sleeper API to test our integration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "59b66cb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching sample data from Sleeper API...\n",
      "\n",
      "1. Fetching NFL players...\n",
      "Total NFL players available: 11391\n",
      "Sample players DataFrame shape: (100, 52)\n",
      "\n",
      "Sample players:\n",
      "          full_name position  team\n",
      "0  Ellis Richardson       TE  None\n",
      "1        Nick Amoah       OL  None\n",
      "2  Malkelm Morrison       CB  None\n",
      "3       Carl Tucker       TE  None\n",
      "4       C.J. Mosley       LB  None\n",
      "5     Samuel Womack       CB   IND\n",
      "6        Ron Parker       FS  None\n",
      "7      Le'Veon Bell       RB    TB\n",
      "8      Matt Seybert       TE  None\n",
      "9       William Gay       CB  None\n",
      "\n",
      "2. Skipping user data (replace 'example_user' with actual username)\n",
      "\n",
      "Data fetching complete!\n",
      "Total NFL players available: 11391\n",
      "Sample players DataFrame shape: (100, 52)\n",
      "\n",
      "Sample players:\n",
      "          full_name position  team\n",
      "0  Ellis Richardson       TE  None\n",
      "1        Nick Amoah       OL  None\n",
      "2  Malkelm Morrison       CB  None\n",
      "3       Carl Tucker       TE  None\n",
      "4       C.J. Mosley       LB  None\n",
      "5     Samuel Womack       CB   IND\n",
      "6        Ron Parker       FS  None\n",
      "7      Le'Veon Bell       RB    TB\n",
      "8      Matt Seybert       TE  None\n",
      "9       William Gay       CB  None\n",
      "\n",
      "2. Skipping user data (replace 'example_user' with actual username)\n",
      "\n",
      "Data fetching complete!\n"
     ]
    }
   ],
   "source": [
    "# For demo purposes, let's fetch some sample data\n",
    "# Note: Replace 'your_sleeper_username' with an actual Sleeper username\n",
    "\n",
    "# Example: Get a user (you can replace this with any public Sleeper username)\n",
    "sample_username = \"example_user\"  # Replace with actual username\n",
    "\n",
    "print(\"Fetching sample data from Sleeper API...\")\n",
    "\n",
    "# 1. Get NFL players (limited sample for performance)\n",
    "print(\"\\n1. Fetching NFL players...\")\n",
    "players_data = sleeper.get_players()\n",
    "if players_data:\n",
    "    print(f\"Total NFL players available: {len(players_data)}\")\n",
    "    \n",
    "    # Convert to DataFrame for easier analysis\n",
    "    players_list = []\n",
    "    for player_id, player_info in list(players_data.items())[:100]:  # First 100 for demo\n",
    "        player_info['sleeper_id'] = player_id\n",
    "        players_list.append(player_info)\n",
    "    \n",
    "    players_df = pd.DataFrame(players_list)\n",
    "    print(f\"Sample players DataFrame shape: {players_df.shape}\")\n",
    "    print(\"\\nSample players:\")\n",
    "    print(players_df[['full_name', 'position', 'team']].head(10))\n",
    "    \n",
    "else:\n",
    "    print(\"Failed to fetch players data\")\n",
    "    players_df = pd.DataFrame()\n",
    "\n",
    "# 2. Try to get user data (if username is provided)\n",
    "user_data = None\n",
    "leagues_data = None\n",
    "\n",
    "if sample_username != \"example_user\":\n",
    "    print(f\"\\n2. Fetching user data for: {sample_username}\")\n",
    "    user_data = sleeper.get_user(sample_username)\n",
    "    \n",
    "    if user_data:\n",
    "        print(f\"User found: {user_data.get('display_name', user_data.get('username'))}\")\n",
    "        \n",
    "        # Get user's leagues\n",
    "        user_id = user_data['user_id']\n",
    "        leagues_data = sleeper.get_user_leagues(user_id)\n",
    "        \n",
    "        if leagues_data:\n",
    "            print(f\"Found {len(leagues_data)} leagues for user\")\n",
    "            leagues_df = pd.DataFrame(leagues_data)\n",
    "            print(\"\\nUser's leagues:\")\n",
    "            print(leagues_df[['name', 'season', 'total_rosters', 'status']].head())\n",
    "        else:\n",
    "            print(\"No leagues found for user\")\n",
    "    else:\n",
    "        print(\"User not found\")\n",
    "else:\n",
    "    print(\"\\n2. Skipping user data (replace 'example_user' with actual username)\")\n",
    "\n",
    "print(\"\\nData fetching complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65c46989",
   "metadata": {},
   "source": [
    "## 7. Data Processing and Validation\n",
    "\n",
    "Process and clean the API response data before inserting into the database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "63c64a12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing player data...\n",
      "Processed 100 players\n",
      "\n",
      "Data types:\n",
      "id                  object\n",
      "player_id           object\n",
      "first_name          object\n",
      "last_name           object\n",
      "full_name           object\n",
      "position            object\n",
      "team                object\n",
      "college             object\n",
      "height              object\n",
      "weight              object\n",
      "age                float64\n",
      "years_exp            int64\n",
      "active                bool\n",
      "injury_status       object\n",
      "fantasy_data_id    float64\n",
      "dtype: object\n",
      "\n",
      "Sample processed data:\n",
      "          full_name position  team   age  years_exp\n",
      "0  Ellis Richardson       TE  None  26.0          3\n",
      "1        Nick Amoah       OL  None   NaN          0\n",
      "2  Malkelm Morrison       CB  None   NaN          1\n",
      "3       Carl Tucker       TE  None  24.0          1\n",
      "4       C.J. Mosley       LB  None  32.0         11\n",
      "\n",
      "Missing values:\n",
      "position            2\n",
      "team               62\n",
      "college             2\n",
      "age                11\n",
      "injury_status      91\n",
      "fantasy_data_id    38\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "def clean_player_data(player_dict):\n",
    "    \"\"\"Clean and validate player data.\"\"\"\n",
    "    cleaned = {\n",
    "        'id': player_dict.get('sleeper_id'),\n",
    "        'player_id': player_dict.get('player_id'),\n",
    "        'first_name': player_dict.get('first_name'),\n",
    "        'last_name': player_dict.get('last_name'),\n",
    "        'full_name': player_dict.get('full_name'),\n",
    "        'position': player_dict.get('position'),\n",
    "        'team': player_dict.get('team'),\n",
    "        'college': player_dict.get('college'),\n",
    "        'height': player_dict.get('height'),\n",
    "        'weight': player_dict.get('weight'),\n",
    "        'age': player_dict.get('age'),\n",
    "        'years_exp': player_dict.get('years_exp'),\n",
    "        'active': player_dict.get('active', True),\n",
    "        'injury_status': player_dict.get('injury_status'),\n",
    "        'fantasy_data_id': player_dict.get('fantasy_data_id')\n",
    "    }\n",
    "    \n",
    "    # Convert numeric fields\n",
    "    for field in ['age', 'years_exp']:\n",
    "        if cleaned[field] is not None:\n",
    "            try:\n",
    "                cleaned[field] = int(cleaned[field])\n",
    "            except (ValueError, TypeError):\n",
    "                cleaned[field] = None\n",
    "    \n",
    "    return cleaned\n",
    "\n",
    "# Process players data if we have it\n",
    "if not players_df.empty:\n",
    "    print(\"Processing player data...\")\n",
    "    \n",
    "    # Clean the data\n",
    "    processed_players = []\n",
    "    for _, player in players_df.iterrows():\n",
    "        cleaned_player = clean_player_data(player.to_dict())\n",
    "        processed_players.append(cleaned_player)\n",
    "    \n",
    "    processed_players_df = pd.DataFrame(processed_players)\n",
    "    \n",
    "    print(f\"Processed {len(processed_players_df)} players\")\n",
    "    print(\"\\nData types:\")\n",
    "    print(processed_players_df.dtypes)\n",
    "    \n",
    "    print(\"\\nSample processed data:\")\n",
    "    print(processed_players_df[['full_name', 'position', 'team', 'age', 'years_exp']].head())\n",
    "    \n",
    "    # Check for missing values\n",
    "    print(\"\\nMissing values:\")\n",
    "    missing_counts = processed_players_df.isnull().sum()\n",
    "    print(missing_counts[missing_counts > 0])\n",
    "    \n",
    "else:\n",
    "    print(\"No player data to process\")\n",
    "    processed_players_df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fecce3a",
   "metadata": {},
   "source": [
    "## 8. Insert Data into Database\n",
    "\n",
    "Insert the processed data into our PostgreSQL database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7ed1b3ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inserting players into database...\n",
      "Existing players in database: 11391\n",
      "Players already exist in database, skipping insert\n",
      "\n",
      "Data insertion complete!\n"
     ]
    }
   ],
   "source": [
    "def insert_players_batch(df, engine):\n",
    "    \"\"\"Insert players data into database using batch insert.\"\"\"\n",
    "    if df.empty:\n",
    "        return 0\n",
    "    \n",
    "    try:\n",
    "        # Use pandas to_sql for efficient batch insert\n",
    "        rows_inserted = df.to_sql(\n",
    "            'players', \n",
    "            engine, \n",
    "            if_exists='append', \n",
    "            index=False,\n",
    "            method='multi'\n",
    "        )\n",
    "        return rows_inserted\n",
    "    except Exception as e:\n",
    "        print(f\"Error inserting players: {e}\")\n",
    "        return 0\n",
    "\n",
    "# Insert sample players data\n",
    "if not processed_players_df.empty:\n",
    "    print(\"Inserting players into database...\")\n",
    "    \n",
    "    try:\n",
    "        # First, let's check if any players already exist\n",
    "        with engine.connect() as conn:\n",
    "            existing_count = conn.execute(text(\"SELECT COUNT(*) FROM players\")).fetchone()[0]\n",
    "            print(f\"Existing players in database: {existing_count}\")\n",
    "        \n",
    "        # Insert new players (avoid duplicates by checking IDs)\n",
    "        if existing_count == 0:\n",
    "            rows_inserted = insert_players_batch(processed_players_df, engine)\n",
    "            print(f\"Inserted {rows_inserted} players into database\")\n",
    "        else:\n",
    "            print(\"Players already exist in database, skipping insert\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Database insert error: {e}\")\n",
    "\n",
    "# Insert user data if available\n",
    "if user_data:\n",
    "    print(\"\\nInserting user data...\")\n",
    "    \n",
    "    user_record = {\n",
    "        'id': user_data['user_id'],\n",
    "        'username': user_data.get('username'),\n",
    "        'display_name': user_data.get('display_name'),\n",
    "        'avatar': user_data.get('avatar')\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        user_df = pd.DataFrame([user_record])\n",
    "        user_df.to_sql('users', engine, if_exists='append', index=False)\n",
    "        print(\"User data inserted successfully\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error inserting user data: {e}\")\n",
    "\n",
    "# Insert leagues data if available\n",
    "if leagues_data:\n",
    "    print(\"\\nInserting leagues data...\")\n",
    "    \n",
    "    try:\n",
    "        # Prepare leagues DataFrame\n",
    "        leagues_df = pd.DataFrame(leagues_data)\n",
    "        leagues_df = leagues_df.rename(columns={'league_id': 'id'})\n",
    "        \n",
    "        # Select only the columns we need\n",
    "        columns_to_keep = ['id', 'name', 'season', 'sport', 'status', \n",
    "                          'season_type', 'total_rosters']\n",
    "        leagues_df = leagues_df[columns_to_keep]\n",
    "        \n",
    "        leagues_df.to_sql('leagues', engine, if_exists='append', index=False)\n",
    "        print(f\"Inserted {len(leagues_df)} leagues into database\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error inserting leagues data: {e}\")\n",
    "\n",
    "print(\"\\nData insertion complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17d65ff6",
   "metadata": {},
   "source": [
    "## 9. Verify Database Operations\n",
    "\n",
    "Query the database to verify successful data insertion and explore our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "86a71021",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Verifying database operations...\n",
      "\n",
      "📊 Users: 0 records\n",
      "📊 Leagues: 0 records\n",
      "📊 Players: 11391 records\n",
      "Sample players data:\n",
      "   id player_id first_name  last_name        full_name position team          college height weight  age  years_exp  active injury_status fantasy_data_id rotowire_id rotoworld_id                 created_at                 updated_at\n",
      " 6462      6462      Ellis Richardson Ellis Richardson       TE None Georgia Southern     75    245 26.0          3    True          None           21427       14134         None 2025-08-10 21:36:13.077348 2025-08-10 21:36:13.077353\n",
      "11255     11255       Nick      Amoah       Nick Amoah       OL None         UC Davis     74    306  NaN          0    True          None            None        None         None 2025-08-10 21:36:13.077356 2025-08-10 21:36:13.077357\n",
      " 8842      8842    Malkelm   Morrison Malkelm Morrison       CB None             Army     70    186  NaN          1    True          None            None       16558         None 2025-08-10 21:36:13.077359 2025-08-10 21:36:13.077360\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "📊 Rosters: 0 records\n",
      "📊 Matchups: 0 records\n"
     ]
    }
   ],
   "source": [
    "# Verify data insertion by querying each table\n",
    "print(\"Verifying database operations...\\n\")\n",
    "\n",
    "tables_to_check = ['users', 'leagues', 'players', 'rosters', 'matchups']\n",
    "\n",
    "for table in tables_to_check:\n",
    "    try:\n",
    "        # Get row count\n",
    "        with engine.connect() as conn:\n",
    "            count_result = conn.execute(text(f\"SELECT COUNT(*) FROM {table}\"))\n",
    "            count = count_result.fetchone()[0]\n",
    "            print(f\"📊 {table.capitalize()}: {count} records\")\n",
    "            \n",
    "            # Show sample data if records exist\n",
    "            if count > 0:\n",
    "                sample_query = f\"SELECT * FROM {table} LIMIT 3\"\n",
    "                sample_df = pd.read_sql(sample_query, conn)\n",
    "                print(f\"Sample {table} data:\")\n",
    "                print(sample_df.to_string(index=False))\n",
    "                print(\"\\n\" + \"-\"*80 + \"\\n\")\n",
    "                \n",
    "    except Exception as e:\n",
    "        print(f\"Error checking {table}: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dff5cb5",
   "metadata": {},
   "source": [
    "## Summary and Next Steps\n",
    "\n",
    "🎉 **Congratulations!** You've successfully:\n",
    "\n",
    "1. ✅ Set up a PostgreSQL database for fantasy football data\n",
    "2. ✅ Connected to the Sleeper API\n",
    "3. ✅ Created database tables for users, leagues, players, rosters, and matchups\n",
    "4. ✅ Fetched and processed sample data from Sleeper\n",
    "5. ✅ Inserted data into the database\n",
    "6. ✅ Verified successful data operations\n",
    "\n",
    "### Next Steps for Your Fantasy Football Analytics Platform:\n",
    "\n",
    "1. **Data Collection Automation**\n",
    "   - Set up scheduled jobs to regularly sync data from Sleeper\n",
    "   - Implement incremental updates to avoid duplicates\n",
    "   - Add error handling and logging\n",
    "\n",
    "2. **Advanced Analytics**\n",
    "   - Player performance trends\n",
    "   - League competitiveness analysis\n",
    "   - Waiver wire recommendations\n",
    "   - Trade analysis and recommendations\n",
    "\n",
    "3. **Data Science Features**\n",
    "   - Machine learning models for player projections\n",
    "   - Clustering analysis for player similarities\n",
    "   - Time series forecasting for season outcomes\n",
    "\n",
    "4. **Visualization Dashboard**\n",
    "   - Interactive plots with Plotly/Dash\n",
    "   - League standings and matchup visualizations\n",
    "   - Player performance heatmaps\n",
    "\n",
    "5. **API Extensions**\n",
    "   - Integrate additional data sources (ESPN, Yahoo, etc.)\n",
    "   - Add real-time game updates\n",
    "   - Include injury reports and news\n",
    "\n",
    "### Configuration Notes:\n",
    "- Remember to update your `.env` file with actual database credentials\n",
    "- Replace the sample username with your actual Sleeper username\n",
    "- Consider implementing database migrations for schema changes\n",
    "\n",
    "Happy analyzing! 🏈📊"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "118dd5dc",
   "metadata": {},
   "source": [
    "## 10. Using the PostgreSQL Helper Utility\n",
    "\n",
    "Now that we have data in our database, let's use the custom PostgreSQL helper utility to make querying easier and more convenient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6c823a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the PostgreSQL helper\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Add project root to path for imports\n",
    "project_root = Path().cwd().parent if 'notebooks' in str(Path().cwd()) else Path().cwd()\n",
    "sys.path.insert(0, str(project_root))\n",
    "\n",
    "from src.utils.pgsql import pg_df, pg_quick_stats, pg_list_tables\n",
    "\n",
    "print(\"🔗 PostgreSQL Helper Imported Successfully!\")\n",
    "\n",
    "# Test basic functionality\n",
    "print(\"\\n1. Database Tables Overview:\")\n",
    "tables_df = pg_list_tables()\n",
    "print(tables_df.to_string(index=False))\n",
    "\n",
    "# Example 1: Simple query using pg_df\n",
    "print(\"\\n2. Simple Query - Top 10 Quarterbacks:\")\n",
    "query1 = \"\"\"\n",
    "SELECT full_name, team, age, years_exp\n",
    "FROM players \n",
    "WHERE position = 'QB' AND active = true AND team IS NOT NULL\n",
    "ORDER BY years_exp DESC, age ASC\n",
    "LIMIT 10\n",
    "\"\"\"\n",
    "qb_df = pg_df(query1)\n",
    "print(qb_df.to_string(index=False))\n",
    "\n",
    "# Example 2: Parameterized query\n",
    "print(\"\\n3. Parameterized Query - Players by Team:\")\n",
    "query2 = \"\"\"\n",
    "SELECT position, COUNT(*) as player_count\n",
    "FROM players \n",
    "WHERE team = :team_name AND active = :is_active\n",
    "GROUP BY position\n",
    "ORDER BY player_count DESC\n",
    "\"\"\"\n",
    "team_df = pg_df(query2, {'team_name': 'BUF', 'is_active': True})\n",
    "print(f\"Buffalo Bills Active Players by Position:\")\n",
    "print(team_df.to_string(index=False))\n",
    "\n",
    "# Example 3: Multi-line analytical query\n",
    "print(\"\\n4. Advanced Query - Team Analysis:\")\n",
    "query3 = \"\"\"\n",
    "SELECT \n",
    "    team,\n",
    "    COUNT(*) as total_players,\n",
    "    COUNT(CASE WHEN position = 'QB' THEN 1 END) as quarterbacks,\n",
    "    COUNT(CASE WHEN position = 'RB' THEN 1 END) as running_backs,\n",
    "    COUNT(CASE WHEN position = 'WR' THEN 1 END) as wide_receivers,\n",
    "    COUNT(CASE WHEN position = 'TE' THEN 1 END) as tight_ends,\n",
    "    ROUND(AVG(age), 1) as avg_age\n",
    "FROM players \n",
    "WHERE active = true AND team IS NOT NULL\n",
    "GROUP BY team\n",
    "ORDER BY total_players DESC\n",
    "LIMIT 5\n",
    "\"\"\"\n",
    "analysis_df = pg_df(query3)\n",
    "print(\"Top 5 Teams by Player Count with Position Breakdown:\")\n",
    "print(analysis_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4d0afb1",
   "metadata": {},
   "source": [
    "### Key Features of the PostgreSQL Helper:\n",
    "\n",
    "1. **Simple Function Call**: `pg_df(query)` - Pass any SQL query as a string and get back a pandas DataFrame\n",
    "2. **Parameterized Queries**: Use `:parameter_name` in your SQL and pass a dictionary of parameters\n",
    "3. **Multi-line Queries**: Write readable, formatted SQL queries across multiple lines\n",
    "4. **Built-in Utilities**: \n",
    "   - `pg_list_tables()` - List all tables with row counts\n",
    "   - `pg_quick_stats(table_name)` - Get quick statistics for any table\n",
    "   - `pg_test_connection()` - Test database connectivity\n",
    "\n",
    "### Common Usage Patterns:\n",
    "\n",
    "```python\n",
    "# Import the helper\n",
    "from src.utils.pgsql import pg_df\n",
    "\n",
    "# Pattern 1: Simple query\n",
    "df = pg_df(\"SELECT * FROM players WHERE position = 'QB' LIMIT 10\")\n",
    "\n",
    "# Pattern 2: Multi-line query with formatting\n",
    "query = '''\n",
    "SELECT \n",
    "    full_name,\n",
    "    position,\n",
    "    team,\n",
    "    age\n",
    "FROM players \n",
    "WHERE active = true\n",
    "ORDER BY age DESC\n",
    "LIMIT 20\n",
    "'''\n",
    "df = pg_df(query)\n",
    "\n",
    "# Pattern 3: Parameterized query for safety\n",
    "query = \"SELECT * FROM players WHERE team = :team AND position = :pos\"\n",
    "df = pg_df(query, {'team': 'BUF', 'pos': 'QB'})\n",
    "```\n",
    "\n",
    "This makes database querying much more convenient for data analysis and exploration!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
